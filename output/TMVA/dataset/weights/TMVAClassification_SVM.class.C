// Class: ReadSVM
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : SVM::SVM
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.38/00       [402944]
Creator        : ooconnor
Date           : Tue Feb  3 10:45:38 2026
Host           : Linux buildvm-x86-26.rdu3.fedoraproject.org 6.17.1-300.fc43.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Oct 6 15:37:21 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /home/lar/ooconnor/larsoft_testing/srcs/sbndcode/sbndcode/Workshop/Analysis/output/TMVA
Training events: 296
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
VarTransform: "Norm" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
Gamma: "2.500000e-01" [RBF kernel parameter: Gamma (size of the Kernel)]
Tol: "1.000000e-03" [Tolerance parameter]
# Default:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
VerbosityLevel: "Default" [Verbosity level]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
Kernel: "RBF" [Pick which kernel ( RBF or MultiGauss )]
Order: "3" [Polynomial Kernel parameter: polynomial order]
Theta: "1.000000e+00" [Polynomial Kernel parameter: polynomial theta]
GammaList: "" [MultiGauss parameters]
Tune: "All" [Tune Parameters]
KernelList: "None" [Sum or product of kernels]
Loss: "hinge" [Loss function]
C: "1.000000e+00" [Cost parameter]
MaxIter: "1000" [Maximum number of training loops]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 5
trackCount                    trackCount                    trackCount                    trackCount                                                      'F'    [0,5]
showerCount                   showerCount                   showerCount                   showerCount                                                     'F'    [0,7]
RecoVertexX                   RecoVertexX                   RecoVertexX                   RecoVertexX                                                     'F'    [-9999,201.21421814]
RecoVertexY                   RecoVertexY                   RecoVertexY                   RecoVertexY                                                     'F'    [-9999,203.759918213]
RecoVertexZ                   RecoVertexZ                   RecoVertexZ                   RecoVertexZ                                                     'F'    [-9999,504.029144287]
NSpec 0


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadSVM : public IClassifierReader {

 public:

   // constructor
   ReadSVM( std::vector<std::string>& theInputVars )
      : IClassifierReader(),
        fClassName( "ReadSVM" ),
        fNvars( 5 )
   {
      // the training input variables
      const char* inputVars[] = { "trackCount", "showerCount", "RecoVertexX", "RecoVertexY", "RecoVertexZ" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = -1;
      fVmax[0] = 1;
      fVmin[1] = -1;
      fVmax[1] = 1;
      fVmin[2] = -1;
      fVmax[2] = 1;
      fVmin[3] = -1;
      fVmax[3] = 0.99999988079071;
      fVmin[4] = -1;
      fVmax[4] = 1;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';

      // initialize constants
      Initialize();

      // initialize transformation
      InitTransform();
   }

   // destructor
   virtual ~ReadSVM() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const override;

 private:

   // method-specific destructor
   void Clear();

   // input variable transformation

   double fOff_1[3][5];
   double fScal_1[3][5];
   void InitTransform_1();
   void Transform_1( std::vector<double> & iv, int sigOrBgd ) const;
   void InitTransform();
   void Transform( std::vector<double> & iv, int sigOrBgd ) const;

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   double fVmin[5];
   double fVmax[5];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[5];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   // not implemented for class: "ReadSVM"
   float        fBparameter;
   int          fNOfSuppVec;
   static float fAllSuppVectors[][272];
   static float fAlphaTypeCoef[272];

   // Kernel parameter(s) 
   float fGamma;
};

inline void ReadSVM::Initialize() 
{
   fBparameter = 0.993151485919952;
   fNOfSuppVec = 272;
   fGamma = 0.25;
}

inline double ReadSVM::GetMvaValue__(const std::vector<double>& inputValues ) const
{
   double mvaval = 0; 
   double temp = 0; 

   for (int ievt = 0; ievt < fNOfSuppVec; ievt++ ){
      temp = 0;
      for ( unsigned int ivar = 0; ivar < GetNvar(); ivar++ ) {
         temp += (fAllSuppVectors[ivar][ievt] - inputValues[ivar])  
               * (fAllSuppVectors[ivar][ievt] - inputValues[ivar]); 
      }
      mvaval += fAlphaTypeCoef[ievt] * exp( -fGamma * temp ); 
   }
   mvaval -= fBparameter;
   return 1./(1. + exp(mvaval));
}
// Clean up
inline void ReadSVM::Clear() 
{
   // nothing to clear 
}

float ReadSVM::fAlphaTypeCoef[] =
{ 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.995449364185333, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.979771256446838, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.915679037570953, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.908559441566467, -0.995516955852509, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -1, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.012512331828475, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.00638720951974392, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.55230838060379, 0.0544444434344769, 0.0544444434344769, -0.358049988746643, 0.0544444434344769, 0.0544444434344769, -0.586760520935059, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.158348843455315, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.492207288742065, -1, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.165459841489792, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.0146357454359531, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.592630088329315, 0.0544444434344769, 0.0544444434344769, -0.00877795182168484, 0.0544444434344769, -0.0687534511089325, 0.0544444434344769, -0.663920819759369, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -1, -0.0289223678410053, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.00275306403636932, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.0445264354348183, -0.364484578371048, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.892523527145386, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.00244318367913365, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.0549160987138748, 0.0544444434344769, -0.023563738912344, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.0566016249358654, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, 0.0544444434344769, -0.0976392775774002, -0.022562388330698, 0.0544444434344769 };

float ReadSVM::fAllSuppVectors[][272] =
{
   { 0.600000023841858, -0.199999988079071, -0.600000023841858, -0.600000023841858, -0.199999988079071, -1, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.199999988079071, -1, -1, -0.600000023841858, -0.199999988079071, -0.600000023841858, -0.600000023841858, -1, -0.199999988079071, -0.600000023841858, -0.199999988079071, 0.200000047683716, 0.600000023841858, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, 0.200000047683716, 0.200000047683716, -0.600000023841858, 0.200000047683716, 0.200000047683716, -0.199999988079071, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, -1, -0.600000023841858, -0.199999988079071, 0.600000023841858, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.600000023841858, -0.600000023841858, -1, -0.199999988079071, 0.600000023841858, -1, -0.600000023841858, 0.600000023841858, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.199999988079071, -1, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.199999988079071, 0.200000047683716, 0.200000047683716, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.600000023841858, 0.200000047683716, -0.199999988079071, 0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.199999988079071, 0.200000047683716, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.600000023841858, 0.200000047683716, -1, 0.200000047683716, -0.600000023841858, 0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.600000023841858, -0.600000023841858, -1, -0.199999988079071, 0.600000023841858, 0.200000047683716, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.199999988079071, -0.600000023841858, -1, -0.199999988079071, -0.600000023841858, 0.600000023841858, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.199999988079071, 0.200000047683716, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.199999988079071, -0.600000023841858, -1, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.199999988079071, -0.199999988079071, -1, -0.600000023841858, -0.199999988079071, -0.199999988079071, 0.200000047683716, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, -1, -0.199999988079071, 0.200000047683716, -0.199999988079071, -1, -0.199999988079071, -0.199999988079071, -0.600000023841858, 0.600000023841858, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.199999988079071, -0.199999988079071, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.600000023841858, -0.199999988079071, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.199999988079071, -1, -0.199999988079071, -0.199999988079071, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.600000023841858, -1, 0.600000023841858, -0.600000023841858, -1, -0.600000023841858, -0.600000023841858, -0.199999988079071, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.199999988079071, -0.199999988079071, 0.200000047683716, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.600000023841858, -0.600000023841858, -0.600000023841858, 0.200000047683716, -0.199999988079071, -0.600000023841858, -0.199999988079071, -0.199999988079071, 0.200000047683716, -0.199999988079071, -1, 0.200000047683716, -0.199999988079071, -0.199999988079071, 0.600000023841858, 0.200000047683716, 0.200000047683716, -0.600000023841858, -0.199999988079071, -1, -0.199999988079071, -0.199999988079071, 1, 0.600000023841858, -0.199999988079071, -1, -0.600000023841858, -0.600000023841858, -1, -0.600000023841858, -0.600000023841858 }, 

   { -1, -1, -1, -0.428571403026581, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -1, -0.428571403026581, -1, -1, -0.714285731315613, -1, -1, -0.714285731315613, -1, -0.714285731315613, -1, -0.428571403026581, -1, -1, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.428571403026581, -1, -1, -0.714285731315613, -1, -0.714285731315613, -1, -0.714285731315613, -1, -1, -0.714285731315613, -1, -1, -1, -0.714285731315613, -1, -0.714285731315613, -1, -0.714285731315613, -1, -0.714285731315613, -1, -1, -0.714285731315613, -1, -0.714285731315613, -0.428571403026581, -0.714285731315613, -0.428571403026581, -0.714285731315613, -1, -1, -1, -1, -0.714285731315613, -1, -0.714285731315613, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.428571403026581, -1, -1, -0.714285731315613, -1, -1, -0.428571403026581, -0.714285731315613, -1, -0.714285731315613, -0.714285731315613, -1, -0.714285731315613, -0.714285731315613, -1, -1, -0.714285731315613, -0.714285731315613, -1, -0.714285731315613, -1, -0.428571403026581, -0.714285731315613, -1, -0.142857074737549, -0.714285731315613, -1, -1, -0.714285731315613, -1, -0.714285731315613, -0.428571403026581, -0.714285731315613, -1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.714285731315613, -0.714285731315613, -1, -1, -0.428571403026581, -0.428571403026581, -1, -1, -1, -1, -1, -1, -1, -0.714285731315613, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0.142857193946838, -0.714285731315613, -1, -0.714285731315613, -1, -1, 1, -0.714285731315613, -1, -1, -1, -1, -1, -1, -1, -1, -1, -0.714285731315613, -0.714285731315613, -1, -1, -0.714285731315613, -0.714285731315613, -0.428571403026581, -0.714285731315613, -1, -1, -1, -0.714285731315613, -1, -1, -1, -0.714285731315613, -0.714285731315613, -1, -1, -1, -0.714285731315613, -1, -1, -1, -1, -0.142857074737549, -0.142857074737549, -1, -1, -1, -0.714285731315613, -1, -0.714285731315613, -1, -1, -1, -1, -0.714285731315613, -1, -1, -0.714285731315613, -1, -0.428571403026581, -1, -0.714285731315613, -0.714285731315613, -0.428571403026581, -1, 0.142857193946838, -1, -0.714285731315613, -0.714285731315613, -1, -1, -0.428571403026581, -0.714285731315613, -1, -1, -1, -0.714285731315613, -0.714285731315613, -1, -1, -1, -0.714285731315613, -1, -1, -1, -0.428571403026581, -1, -1, -0.428571403026581, -1 }, 

   { 0.975188851356506, 0.931113004684448, 0.956543207168579, 0.933124780654907, 0.956921100616455, -1, 0.98842442035675, 0.92379891872406, 0.931717753410339, 0.95850145816803, 0.965494394302368, -1, -1, 0.941116690635681, 0.979226469993591, 1, 0.972283244132996, -1, 0.982961297035217, 0.975987434387207, 0.952976107597351, 0.932332038879395, 0.92764139175415, 0.935566067695618, 0.988015174865723, 0.938464164733887, 0.983644127845764, 0.938461780548096, 0.974789023399353, 0.953579664230347, 0.940635681152344, 0.947787165641785, 0.938599109649658, 0.997474670410156, 0.988386511802673, 0.947659730911255, 0.931617736816406, 0.97539746761322, 0.954398155212402, 0.964899063110352, -1, 0.928596615791321, 0.940019130706787, 0.942517280578613, 0.982680201530457, 0.999932050704956, 0.963780283927917, 0.921087741851807, 0.932077288627625, -1, 0.928582668304443, 0.956466913223267, -1, 0.934830188751221, 0.965811133384705, 0.988258719444275, 0.973651051521301, 0.951357960700989, 0.964041113853455, -1, 0.9256831407547, 0.923897385597229, 0.944761037826538, 0.956562876701355, 0.937408328056335, 0.927204251289368, 0.942040205001831, 0.971375703811646, 0.955296039581299, 0.994140982627869, 0.969099998474121, 0.992485046386719, 0.968785881996155, 0.991450905799866, 0.94204306602478, 0.970543146133423, 0.964979290962219, 0.92367160320282, 0.973331212997437, 0.955647468566895, 0.947894215583801, 0.933419466018677, 0.998568415641785, 0.982840538024902, 0.921114921569824, 0.962601900100708, 0.937896609306335, 0.960792064666748, 0.93524956703186, 0.960121870040894, 0.949976801872253, 0.921080112457275, 0.94868791103363, 0.996631026268005, 0.929160356521606, 0.981475591659546, 0.944675087928772, 0.987757802009583, 0.928004622459412, 0.989156246185303, 0.948185443878174, 0.951155185699463, 0.954258441925049, 0.974973320960999, 0.98622453212738, 0.997556805610657, 0.973787903785706, 0.960631012916565, 0.968007922172546, 0.952637791633606, -1, 0.982797145843506, 0.975418329238892, 0.957949757575989, 0.949790716171265, 0.963160276412964, 0.977019667625427, 0.958331227302551, 0.966159224510193, -1, 0.991605281829834, 0.999916553497314, 0.92634117603302, 0.939005255699158, 0.963559746742249, 0.947158455848694, 0.932310581207275, 0.93631112575531, 0.975090980529785, 0.958387732505798, 0.951901912689209, 0.966831684112549, 0.964571714401245, 0.960262656211853, -1, 0.946007251739502, 0.957751035690308, 0.94594943523407, 0.9992835521698, 0.946613669395447, 0.947380661964417, 0.981078624725342, 0.922948598861694, 0.967726707458496, 0.987300992012024, 0.982998967170715, 0.964523673057556, 0.922965049743652, 0.965522408485413, 0.958546996116638, 0.986159205436707, 0.987379312515259, 0.934195637702942, 0.946706295013428, 0.927241206169128, 0.936941862106323, 0.947219848632812, 0.9569993019104, 0.928662300109863, 0.939975023269653, 0.964810967445374, 0.951324582099915, 0.966948509216309, 0.94160795211792, 0.998320937156677, 0.99223268032074, 0.972382426261902, 0.999954462051392, 0.951763987541199, 0.940012216567993, 0.930486679077148, 0.985522150993347, 0.963754296302795, 0.95326566696167, 0.996163606643677, -1, 0.951054453849792, 0.940075755119324, 0.943598389625549, 0.985689878463745, 0.952483415603638, -1, 0.938053607940674, 0.943086981773376, 0.937858819961548, 0.957930445671082, 0.962135434150696, 0.982078790664673, 0.969105362892151, 0.947053670883179, -1, 0.961321115493774, 0.925888299942017, 0.93440854549408, -1, 0.949493646621704, 0.967956304550171, 0.94240415096283, 0.924769163131714, 0.957812309265137, 0.987969279289246, 0.96689760684967, 0.933414578437805, 0.972947001457214, 0.992470145225525, 0.989128470420837, 0.934886932373047, 0.938687562942505, 0.967984557151794, 0.992465972900391, 0.979103565216064, 0.935763716697693, 0.998868584632874, 0.965324759483337, 0.986551761627197, 0.933594465255737, -1, 0.991570711135864, 0.967831969261169, 0.972650408744812, 0.965412259101868, 0.928945302963257, 0.971391201019287, -1, 0.94331693649292, 0.994024157524109, -1, 0.999982595443726, 0.923203229904175, 0.92563271522522, 0.958667993545532, 0.994997262954712, 0.989964008331299, 0.965610861778259, 0.936668395996094, 0.949309706687927, 0.982135653495789, 0.949745893478394, 0.980314135551453, 0.978811144828796, 0.947755813598633, 0.962530374526978, 0.963916420936584, 0.966684222221375, 0.990659356117249, 0.952313780784607, 0.92737865447998, 0.973028898239136, 0.935636758804321, 0.945003151893616, 0.980464220046997, -1, 0.929702401161194, 0.976465582847595, 0.951920866966248, 0.927876472473145, 0.940662860870361, 0.984681129455566, 0.999772787094116, 0.980252981185913, -1, 0.96383273601532, 0.966719150543213, 0.958123445510864, 0.939438104629517, 0.993804574012756, -1, 0.929937720298767, 0.991745352745056, -1, 0.975953221321106, 0.949973464012146 }, 

   { 0.974251866340637, 0.957183361053467, 0.925162792205811, 0.946370005607605, 0.980647444725037, -1, 0.975190281867981, 0.962532877922058, 0.976250052452087, 0.996187925338745, 0.996086478233337, -1, -1, 0.979945778846741, 0.975793123245239, 0.92629611492157, 0.958148121833801, -1, 0.972592353820801, 0.927554607391357, 0.922365307807922, 0.961586833000183, 0.993019342422485, 0.974290370941162, 0.96787166595459, 0.954699158668518, 0.964150667190552, 0.999813675880432, 0.965006947517395, 0.960188627243042, 0.963817358016968, 0.923096895217896, 0.983938336372375, 0.953032374382019, 0.994988441467285, 0.988840103149414, 0.96477472782135, 0.955266356468201, 0.936248779296875, 0.982432126998901, -1, 0.975948929786682, 0.923617959022522, 0.921726822853088, 0.980633854866028, 0.95664370059967, 0.958844900131226, 0.998011112213135, 0.921014189720154, -1, 0.963018298149109, 0.931620597839355, -1, 0.944608569145203, 0.960890173912048, 0.94436514377594, 0.982021927833557, 0.957470893859863, 0.987937688827515, -1, 0.951935410499573, 0.999928951263428, 0.975237369537354, 0.963905453681946, 0.951977133750916, 0.973212599754333, 0.956199884414673, 0.939199566841125, 0.982311367988586, 0.98873233795166, 0.939026832580566, 0.966418385505676, 0.973684906959534, 0.976581215858459, 0.971298336982727, 0.953433990478516, 0.947213768959045, 0.982451200485229, 0.935522556304932, 0.936445832252502, 0.960105180740356, 0.936993837356567, 0.928123712539673, 0.98879063129425, 0.944326043128967, 0.990859270095825, 0.976693987846375, 0.922238349914551, 0.999862909317017, 0.943029880523682, 0.963527917861938, 0.937661409378052, 0.955625057220459, 0.973423957824707, 0.966180801391602, 0.997772574424744, 0.938829302787781, 0.949574708938599, 0.938711404800415, 0.924370169639587, 0.94165027141571, 0.939052700996399, 0.940473318099976, 0.972537755966187, 0.941258549690247, 0.944651484489441, 0.985880136489868, 0.946324348449707, 0.975406765937805, 0.955381393432617, -1, 0.925873041152954, 0.98514449596405, 0.941202282905579, 0.950207591056824, 0.999406695365906, 0.984086871147156, 0.959946274757385, 0.920525550842285, -1, 0.927368521690369, 0.975516319274902, 0.976935505867004, 0.92064893245697, 0.98796546459198, 0.997256398200989, 0.970749855041504, 0.95360791683197, 0.998573422431946, 0.986125230789185, 0.958927273750305, 0.923776865005493, 0.932250022888184, 0.926999092102051, -1, 0.964775443077087, 0.96813702583313, 0.987453937530518, 0.92769181728363, 0.956141352653503, 0.942031502723694, 0.934075713157654, 0.980604290962219, 0.994853734970093, 0.991014003753662, 0.937847971916199, 0.966723442077637, 0.965135335922241, 0.981566071510315, 0.976876735687256, 0.983894824981689, 0.949464797973633, 0.992922306060791, 0.994640588760376, 0.973732709884644, 0.937991976737976, 0.956584930419922, 0.948661208152771, 0.99055027961731, 0.99650514125824, 0.96619188785553, 0.96430492401123, 0.961321473121643, 0.978913426399231, 0.985338807106018, 0.963302969932556, 0.9238201379776, 0.922680377960205, 0.994674921035767, 0.935445547103882, 0.999443411827087, 0.948011517524719, 0.9609135389328, 0.924501657485962, 0.999486923217773, -1, 0.983019471168518, 0.986224412918091, 0.985498428344727, 0.965104341506958, 0.974289059638977, -1, 0.997770667076111, 0.956597924232483, 0.989275574684143, 0.954268574714661, 0.997113704681396, 0.949854016304016, 0.960783720016479, 0.941064596176147, -1, 0.927725553512573, 0.963923573493958, 0.969536781311035, -1, 0.964696049690247, 0.977057099342346, 0.958911895751953, 0.937344551086426, 0.999995112419128, 0.937701344490051, 0.954763293266296, 0.979621767997742, 0.948384404182434, 0.936134099960327, 0.953117728233337, 0.929120659828186, 0.946844100952148, 0.983281493186951, 0.937474131584167, 0.937507271766663, 0.961919546127319, 0.995367884635925, 0.974958419799805, 0.947743058204651, 0.972956657409668, -1, 0.960187196731567, 0.927568316459656, 0.967854022979736, 0.944110155105591, 0.946117401123047, 0.920629024505615, -1, 0.980850458145142, 0.969311594963074, -1, 0.935740113258362, 0.99999988079071, 0.952240705490112, 0.981964468955994, 0.944297671318054, 0.922866821289062, 0.971398234367371, 0.967571139335632, 0.924113988876343, 0.996262431144714, 0.997774124145508, 0.961376667022705, 0.978365182876587, 0.95247220993042, 0.946310043334961, 0.982916831970215, 0.96383261680603, 0.93865168094635, 0.961229562759399, 0.933436512947083, 0.9819016456604, 0.93756091594696, 0.985268950462341, 0.983081221580505, -1, 0.989290118217468, 0.975196361541748, 0.994446754455566, 0.958091616630554, 0.945322871208191, 0.978707194328308, 0.928760051727295, 0.993751645088196, -1, 0.962059855461121, 0.959236979484558, 0.990760087966919, 0.920336246490479, 0.929029583930969, -1, 0.985161900520325, 0.923448204994202, -1, 0.941876530647278, 0.958059906959534 }, 

   { 0.918674945831299, 0.938552379608154, 0.908193230628967, 0.921564698219299, 0.971970200538635, -1, 0.905016422271729, 0.937942981719971, 0.989781618118286, 0.934692621231079, 0.941749930381775, -1, -1, 0.907519817352295, 0.963344693183899, 0.984210133552551, 0.93038809299469, -1, 0.958156228065491, 0.943935871124268, 0.974979281425476, 0.978647589683533, 0.981935620307922, 0.96767520904541, 0.937381744384766, 0.993613839149475, 0.944037795066833, 0.936078906059265, 0.985807299613953, 0.916218519210815, 0.93798291683197, 0.938632249832153, 0.964593529701233, 0.939524531364441, 0.940203428268433, 0.91544497013092, 0.919399976730347, 0.920830488204956, 0.906664252281189, 0.965591549873352, -1, 0.964006662368774, 0.904995083808899, 0.996230244636536, 0.905027389526367, 0.969645261764526, 0.922359704971313, 0.993484258651733, 0.975678563117981, -1, 0.970655083656311, 0.910061478614807, -1, 0.984408497810364, 0.992417216300964, 0.905007481575012, 0.958603501319885, 0.909783720970154, 0.968238115310669, -1, 0.925438165664673, 0.969614863395691, 0.989945292472839, 0.973465800285339, 0.951001644134521, 0.978357672691345, 0.926205635070801, 0.914780735969543, 0.94245433807373, 0.994341850280762, 0.95125937461853, 0.987065672874451, 0.990792870521545, 0.960585236549377, 0.9933922290802, 0.92579972743988, 0.962541341781616, 0.931354284286499, 0.904999375343323, 0.948138475418091, 0.915418028831482, 0.963296294212341, 0.995195746421814, 0.966099262237549, 0.947428107261658, 0.905045032501221, 0.948158740997314, 0.994295239448547, 0.996599197387695, 0.98168683052063, 0.957669734954834, 0.927086353302002, 0.939701557159424, 0.933158278465271, 0.951746106147766, 0.989235997200012, 0.966574907302856, 0.913541674613953, 0.905032396316528, 1, 0.990679740905762, 0.956227898597717, 0.951472163200378, 0.905027747154236, 0.905082106590271, 0.946112871170044, 0.927958250045776, 0.908420205116272, 0.905043840408325, 0.950902819633484, -1, 0.905497312545776, 0.994085431098938, 0.984093308448792, 0.985395193099976, 0.929982304573059, 0.923825025558472, 0.905007719993591, 0.911066055297852, -1, 0.987148642539978, 0.933330416679382, 0.934537172317505, 0.991254210472107, 0.920413970947266, 0.90948486328125, 0.910359025001526, 0.906782507896423, 0.971683025360107, 0.905012726783752, 0.926335573196411, 0.90501880645752, 0.971342921257019, 0.912166714668274, -1, 0.932151079177856, 0.915712237358093, 0.980710744857788, 0.913131475448608, 0.905012130737305, 0.965359568595886, 0.923760056495667, 0.915228366851807, 0.912128806114197, 0.984346270561218, 0.945228934288025, 0.926603078842163, 0.935402154922485, 0.967889904975891, 0.994466066360474, 0.972605586051941, 0.949381113052368, 0.943099617958069, 0.941221952438354, 0.938775897026062, 0.99233877658844, 0.953191518783569, 0.939505219459534, 0.916656136512756, 0.958305358886719, 0.941227674484253, 0.911772131919861, 0.977807760238647, 0.963171720504761, 0.995972156524658, 0.927483320236206, 0.962115287780762, 0.979214310646057, 0.956330537796021, 0.965529680252075, 0.951973676681519, 0.979234099388123, 0.956234216690063, 0.956254482269287, 0.95429515838623, -1, 0.960166811943054, 0.959357023239136, 0.985087513923645, 0.940462827682495, 0.908839583396912, -1, 0.944220185279846, 0.91968560218811, 0.952403783798218, 0.934723258018494, 0.953698992729187, 0.975171566009521, 0.916106820106506, 0.917527556419373, -1, 0.905048608779907, 0.973335146903992, 0.9050213098526, -1, 0.905039191246033, 0.905045866966248, 0.905042290687561, 0.909105539321899, 0.95921790599823, 0.904985785484314, 0.991528749465942, 0.938009858131409, 0.949256300926208, 0.989223957061768, 0.906698226928711, 0.937578797340393, 0.966048121452332, 0.993708729743958, 0.912943124771118, 0.973465323448181, 0.916991591453552, 0.979004621505737, 0.977568984031677, 0.954095482826233, 0.920511841773987, -1, 0.986934781074524, 0.948961496353149, 0.9878009557724, 0.920853614807129, 0.90501594543457, 0.938634514808655, -1, 0.927006959915161, 0.925690531730652, -1, 0.961086750030518, 0.992418646812439, 0.940251111984253, 0.987812638282776, 0.950414419174194, 0.905022263526917, 0.962729334831238, 0.986026525497437, 0.956218957901001, 0.989304423332214, 0.951023101806641, 0.966166973114014, 0.942919373512268, 0.912500381469727, 0.98814868927002, 0.975327610969543, 0.958535194396973, 0.943512558937073, 0.975558757781982, 0.971911549568176, 0.993973612785339, 0.929957389831543, 0.95724892616272, 0.917032837867737, -1, 0.966553568840027, 0.946365594863892, 0.959956526756287, 0.905293107032776, 0.942417621612549, 0.905069828033447, 0.995216250419617, 0.907705068588257, -1, 0.935383200645447, 0.928167462348938, 0.966767430305481, 0.907370090484619, 0.905044555664062, -1, 0.953005790710449, 0.904994487762451, -1, 0.91111958026886, 0.951526045799255 }
};

inline double ReadSVM::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!IsStatusClean()) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                << " because status is dirty" << std::endl;
   }
   else {
         // normalise variables
         std::vector<double> iV;
         iV.reserve(inputValues.size());
         int ivar = 0;
         for (std::vector<double>::const_iterator varIt = inputValues.begin();
              varIt != inputValues.end(); varIt++, ivar++) {
            iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
         }
         Transform( iV, -1 );
         retval = GetMvaValue__( iV );
   }

   return retval;
}

//_______________________________________________________________________
inline void ReadSVM::InitTransform_1()
{
   double fMin_1[3][5];
   double fMax_1[3][5];
   // Normalization transformation, initialisation
   fMin_1[0][0] = 0;
   fMax_1[0][0] = 4;
   fScal_1[0][0] = 2.0/(fMax_1[0][0]-fMin_1[0][0]);
   fOff_1[0][0] = fMin_1[0][0]*fScal_1[0][0]+1.;
   fMin_1[1][0] = 0;
   fMax_1[1][0] = 5;
   fScal_1[1][0] = 2.0/(fMax_1[1][0]-fMin_1[1][0]);
   fOff_1[1][0] = fMin_1[1][0]*fScal_1[1][0]+1.;
   fMin_1[2][0] = 0;
   fMax_1[2][0] = 5;
   fScal_1[2][0] = 2.0/(fMax_1[2][0]-fMin_1[2][0]);
   fOff_1[2][0] = fMin_1[2][0]*fScal_1[2][0]+1.;
   fMin_1[0][1] = 0;
   fMax_1[0][1] = 7;
   fScal_1[0][1] = 2.0/(fMax_1[0][1]-fMin_1[0][1]);
   fOff_1[0][1] = fMin_1[0][1]*fScal_1[0][1]+1.;
   fMin_1[1][1] = 0;
   fMax_1[1][1] = 4;
   fScal_1[1][1] = 2.0/(fMax_1[1][1]-fMin_1[1][1]);
   fOff_1[1][1] = fMin_1[1][1]*fScal_1[1][1]+1.;
   fMin_1[2][1] = 0;
   fMax_1[2][1] = 7;
   fScal_1[2][1] = 2.0/(fMax_1[2][1]-fMin_1[2][1]);
   fOff_1[2][1] = fMin_1[2][1]*fScal_1[2][1]+1.;
   fMin_1[0][2] = -9999;
   fMax_1[0][2] = 170.736328125;
   fScal_1[0][2] = 2.0/(fMax_1[0][2]-fMin_1[0][2]);
   fOff_1[0][2] = fMin_1[0][2]*fScal_1[0][2]+1.;
   fMin_1[1][2] = -9999;
   fMax_1[1][2] = 201.21421814;
   fScal_1[1][2] = 2.0/(fMax_1[1][2]-fMin_1[1][2]);
   fOff_1[1][2] = fMin_1[1][2]*fScal_1[1][2]+1.;
   fMin_1[2][2] = -9999;
   fMax_1[2][2] = 201.21421814;
   fScal_1[2][2] = 2.0/(fMax_1[2][2]-fMin_1[2][2]);
   fOff_1[2][2] = fMin_1[2][2]*fScal_1[2][2]+1.;
   fMin_1[0][3] = -9999;
   fMax_1[0][3] = 193.61378479;
   fScal_1[0][3] = 2.0/(fMax_1[0][3]-fMin_1[0][3]);
   fOff_1[0][3] = fMin_1[0][3]*fScal_1[0][3]+1.;
   fMin_1[1][3] = -9999;
   fMax_1[1][3] = 203.759918213;
   fScal_1[1][3] = 2.0/(fMax_1[1][3]-fMin_1[1][3]);
   fOff_1[1][3] = fMin_1[1][3]*fScal_1[1][3]+1.;
   fMin_1[2][3] = -9999;
   fMax_1[2][3] = 203.759918213;
   fScal_1[2][3] = 2.0/(fMax_1[2][3]-fMin_1[2][3]);
   fOff_1[2][3] = fMin_1[2][3]*fScal_1[2][3]+1.;
   fMin_1[0][4] = -9999;
   fMax_1[0][4] = 469.811553955;
   fScal_1[0][4] = 2.0/(fMax_1[0][4]-fMin_1[0][4]);
   fOff_1[0][4] = fMin_1[0][4]*fScal_1[0][4]+1.;
   fMin_1[1][4] = -9999;
   fMax_1[1][4] = 504.029144287;
   fScal_1[1][4] = 2.0/(fMax_1[1][4]-fMin_1[1][4]);
   fOff_1[1][4] = fMin_1[1][4]*fScal_1[1][4]+1.;
   fMin_1[2][4] = -9999;
   fMax_1[2][4] = 504.029144287;
   fScal_1[2][4] = 2.0/(fMax_1[2][4]-fMin_1[2][4]);
   fOff_1[2][4] = fMin_1[2][4]*fScal_1[2][4]+1.;
}

//_______________________________________________________________________
inline void ReadSVM::Transform_1( std::vector<double>& iv, int cls) const
{
   // Normalization transformation
   if (cls < 0 || cls > 2) {
   if (2 > 1 ) cls = 2;
      else cls = 2;
   }
   const int nVar = 5;

   // get indices of used variables

   // define the indices of the variables which are transformed by this transformation
   static std::vector<int> indicesGet;
   static std::vector<int> indicesPut;

   if ( indicesGet.empty() ) {
      indicesGet.reserve(fNvars);
      indicesGet.push_back( 0);
      indicesGet.push_back( 1);
      indicesGet.push_back( 2);
      indicesGet.push_back( 3);
      indicesGet.push_back( 4);
   }
   if ( indicesPut.empty() ) {
      indicesPut.reserve(fNvars);
      indicesPut.push_back( 0);
      indicesPut.push_back( 1);
      indicesPut.push_back( 2);
      indicesPut.push_back( 3);
      indicesPut.push_back( 4);
   }

   static std::vector<double> dv;
   dv.resize(nVar);
   for (int ivar=0; ivar<nVar; ivar++) dv[ivar] = iv[indicesGet.at(ivar)];
   for (int ivar=0;ivar<5;ivar++) {
      double offset = fOff_1[cls][ivar];
      double scale  = fScal_1[cls][ivar];
      iv[indicesPut.at(ivar)] = scale*dv[ivar]-offset;
   }
}

//_______________________________________________________________________
inline void ReadSVM::InitTransform()
{
   InitTransform_1();
}

//_______________________________________________________________________
inline void ReadSVM::Transform( std::vector<double>& iv, int sigOrBgd ) const
{
   Transform_1( iv, sigOrBgd );
}
